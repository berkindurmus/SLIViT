{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbJENh06Okuc+in9xZ3Ie1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berkindurmus/SLIViT/blob/main/SLIViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import torch\n",
        "import torchvision.models as tmodels\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "wgNLU_knoAqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_backbone(model_name):\n",
        "    logging.info(\"Loading ImageNet Model\")\n",
        "    model = tmodels.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n",
        "    return torch.nn.Sequential(*list(model.children())[:-2])\n",
        "def pair(t):\n",
        "    return t if isinstance(t, tuple) else (t, t)\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
        "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x) + x\n",
        "            x = ff(x) + x\n",
        "        return x\n",
        "\n",
        "\n",
        "class SLIViT(nn.Module):\n",
        "    def __init__(self, *, backbone, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool='cls',\n",
        "                 channels=3, dim_head=64, dropout=0., emb_dropout=0.):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.channels=channels\n",
        "        self.image_size=image_size\n",
        "        image_height, image_width = pair(image_size)\n",
        "        patch_height, patch_width = pair(patch_size)\n",
        "        patch_height=patch_height*8\n",
        "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "        num_patches = (image_height // patch_height) * (image_width // patch_width) *channels\n",
        "        patch_dim = patch_height * patch_width\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (c h w) (p1 p2)', p1=patch_height, p2=patch_width),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "        tmp_pos_emb = torch.zeros((1, dim))\n",
        "        orderOSlcs = torch.arange(num_patches)+1\n",
        "        for i in range(num_patches):tmp_pos_emb=torch.concat([tmp_pos_emb,torch.ones((1,dim))*orderOSlcs[i]],axis=0)\n",
        "        self.pos_embedding = nn.Parameter(tmp_pos_emb.reshape((1, tmp_pos_emb.shape[0], tmp_pos_emb.shape[1])))#.cuda()\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "        self.pool = pool\n",
        "        self.to_latent = nn.Identity()\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, img):\n",
        "        #Backone\n",
        "        img = self.backbone(img).reshape((img.shape[0], self.image_size[0], self.channels, self.image_size[1]))\n",
        "        img = img.permute(0, 2, 1, 3)\n",
        "        #Feature Maps to Patches\n",
        "        x = self.to_patch_embedding(img)\n",
        "        b, n, _ = x.shape\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        #Add Slice Order as Positional Embedding for Encoding 3D Spatial Info\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "        x = self.dropout(x)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n",
        "        x = self.to_latent(x)\n",
        "        x = self.mlp_head(x)\n",
        "        x=torch.squeeze(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "EwDcHjhRl_i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Feature Extractor (Backbone)"
      ],
      "metadata": {
        "id": "j0Ycgs0pt8CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = load_backbone('ImageNet')"
      ],
      "metadata": {
        "id": "IPqmIeOOt-ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create SLIViT Model\n"
      ],
      "metadata": {
        "id": "a0CeFmiTt-5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "m_SLIViT=SLIViT(backbone=backbone, image_size=(512, 64), patch_size=64, num_classes=1, dim=256, depth=5, heads=19,\n",
        "    mlp_dim=512, channels=19, dropout=0.3, emb_dropout=0.4)"
      ],
      "metadata": {
        "id": "jmNUOOPjnOmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Generate Random Data"
      ],
      "metadata": {
        "id": "94fGkGEqt3fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nObatch=4\n",
        "nOslices=19\n",
        "nOch=3\n",
        "image_size=(256,256)\n",
        "rand_long_images=torch.rand(nObatch,nOch,nOslices*image_size[0], image_size[1])"
      ],
      "metadata": {
        "id": "lDTuGQYmns6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Make Inference Using Generated Data"
      ],
      "metadata": {
        "id": "ePHEiBx1ty8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores=m_SLIViT(rand_long_images)"
      ],
      "metadata": {
        "id": "etk5U9YOpdaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores.detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO8L57GsplyT",
        "outputId": "3879fe39-433b-4799-aa3e-94b17f41fd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.6059151e-04  3.6952800e-01  1.1123219e+00  1.0020475e+00]\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL2O-dD9ZmRs"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import torch\n",
        "import torchvision.models as tmodels\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "from torch import nn\n",
        "from transformers import AutoModelForImageClassification\n",
        "import torchvision.models as tmodels\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNext(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(ConvNext, self).__init__()\n",
        "        self.model=model\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)[0]\n",
        "        return x"
      ],
      "metadata": {
        "id": "lbFqEJ3I34wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        return self.to_out(out)"
      ],
      "metadata": {
        "id": "-oK6eSpL4Jbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "NMVo3lbu39Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)"
      ],
      "metadata": {
        "id": "45-TKcrs37md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
        "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x) + x\n",
        "            x = ff(x) + x\n",
        "        return x"
        "def pair(t):\n",
        "   return t if isinstance(t, tuple) else (t, t)"
      ],
      "metadata": {
        "id": "BpuG01TW4E-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SLIViT(nn.Module):\n",
        "\n",
        "    def __init__(self, *, backbone, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool='cls',\n",
        "                 channels=3, dim_head=64, dropout=0., emb_dropout=0.):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.channels=channels\n",
        "        image_height, image_width = pair(image_size)\n",
        "        _, patch_width = pair(patch_size)\n",
        "        patch_height=12*patch_width\n",
        "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "        num_patches = (image_height // patch_height) * (image_width // patch_width) *channels\n",
        "        patch_dim = patch_height * patch_width\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (c h w) (p1 p2)', p1=patch_height, p2=patch_width),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "        tmpp = torch.zeros((1, dim))\n",
        "        tmp3 = torch.arange(num_patches) + 1\n",
        "        for i in range(num_patches): tmpp = torch.concat([tmpp, torch.ones((1, dim)) * tmp3[i]], axis=0)\n",
        "        self.pos_embedding = nn.Parameter(tmpp.reshape((1, tmpp.shape[0], tmpp.shape[1])))  # .cuda()\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "        self.pool = pool\n",
        "        self.to_latent = nn.Identity()\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.backbone(x)\n",
        "        x=  x.last_hidden_state\n",
        "        x = x.reshape((x.shape[0], x.shape[1], self.channels, 64))\n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "        x = self.to_patch_embedding(x)\n",
        "        b, n, _ = x.shape\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "        x = self.dropout(x)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n",
        "        x = self.to_latent(x)\n",
        "        x = self.mlp_head(x)\n",
        "        x=torch.squeeze(x)\n",
        "        return x\n",
        "\n",
      ],
      "metadata": {
        "id": "c9z992fYZos2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_backbone(path):\n",
        "    model_tmp = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-tiny-224\", return_dict=False,num_labels=4, ignore_mismatched_sizes=True)\n",
        "    model = ConvNext(model_tmp)\n",
        "    model.load_state_dict(torch.load(path, map_location=torch.device(\"cuda\")))\n",
        "    model = torch.nn.Sequential(*[list(list(model_tmp.children())[0].children())[0], list(list(model_tmp.children())[0].children())[1]])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Xbzo5xJjZsxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slivit=SLIViT(backbone=load_backbone('/path/to/pretrained_convnext.pth'),\n",
        "              image_size=(768, 64), patch_size=64, num_classes=1,\n",
        "              dim=256, depth=5, heads=19, mlp_dim=512, channels=19,\n",
        "              dropout=0.2, emb_dropout=0.1)"
      ],
      "metadata": {
        "id": "tRrcX8G9Fzq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "n_slices=19\n",
        "n_channels=3\n",
        "image_size=(256,256)\n",
        "rand_long_images=torch.rand(batch_size,n_channels,n_slices*image_size[0], image_size[1])\n",
        ""
      ],
      "metadata": {
        "id": "xJd0RWfIGvOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores=slivit(rand_long_images)"
      ],
      "metadata": {
        "id": "bR04N1VgGx0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YXOYvoRGzhO",
        "outputId": "4ddf1eed-f6b2-4296-d025-78b4da0e81df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3907, 0.5755, 0.6620, 0.0644], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}
